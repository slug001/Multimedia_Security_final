# 論文筆記：CrowdGuard - 聯邦學習中的聯合後門檢測 (NDSS 2024)

這篇筆記整理了 NDSS 2024 的論文「CrowdGuard: Federated Backdoor Detection in Federated Learning」。

## 論文基本資訊

*   **論文標題 (英文)：** CrowdGuard: Federated Backdoor Detection in Federated Learning
*   **論文標題 (中文翻譯)：** CrowdGuard：聯邦學習中的聯合後門檢測
*   **發表會議：** NDSS Symposium 2024
*   **論文連結：** https://www.ndss-symposium.org/wp-content/uploads/2024-233-paper.pdf
*   **程式碼連結 ：** 

## 摘要 (繁體中文)

> 聯邦學習 (Federated Learning, FL) 是一種有前景的方法，允許多個客戶端協同訓練深度神經網路 (DNNs) 而無需共享其本地訓練數據。然而，FL 容易受到後門（或目標性中毒）攻擊。這些攻擊由惡意客戶端發起，他們試圖通過在學習到的模型中引入可由精心設計的輸入觸發的特定行為來破壞學習過程。現有的 FL 防護措施有各種局限性：它們可能僅限於特定的數據分佈，或者由於排除良性模型或添加噪聲而降低全局模型的準確性，容易受到自適應的、了解防禦機制的對手攻擊，或者需要服務器訪問本地模型，從而允許數據推斷攻擊。
>
> 本文提出了一種名為 CrowdGuard 的新型防禦機制，它有效地減輕了 FL 中的後門攻擊，並克服了現有技術的不足。它利用客戶端對各個模型的反饋，分析隱藏層中神經元的行為，並通過迭代剪枝方案消除中毒模型。CrowdGuard 採用位於服務器的堆疊式聚類方案來增強其對惡意客戶端反饋的韌性。評估結果表明，CrowdGuard 在各種情境（包括 IID 和 non-IID 數據分佈）下均達到了 100% 的真陽性率和真陰性率。此外，CrowdGuard 能夠抵禦自適應攻擊者，同時保持受保護模型的原始性能。為確保機密性，CrowdGuard 在客戶端和服務器端都利用可信執行環境 (TEEs) 構建了一個安全且保護隱私的架構。

## 核心技術詳細說明

### 1. 目標與貢獻

CrowdGuard 旨在提供一個具備後門攻擊韌性且增強隱私的 FL 架構，克服現有方案的限制。其核心理念是：

*   **利用安全的客戶端反饋迴路 (Secure Client-Feedback-Loop)：** 客戶端進行本地驗證並分析個體神經元行為的變化。
*   **隱藏層後門檢測指標 (Hidden Layer Backdoor Inspection Metric, HLBIM)：** 一種新定義的指標，通過分析模型行為的多次顯著性檢驗和迭代剪枝來識別中毒模型。即使攻擊者能注入不影響最終預測類別的後門，也難以避免改變至少一部分深層神經元的行為。
*   **緩解惡意客戶端的操縱反饋：** 服務器採用多層聚類方案來聚合不同驗證客戶端的反饋。
*   **數據分佈無關性：** 無需對攻擊或數據場景（包括 non-IID）做假設。
*   **隱私保護：** 利用安全隔離區 (Secure Enclaves / TEEs) 和遠程證明 (Remote Attestation) 來防止對本地模型的未授權訪問，即使在客戶端反饋過程中也是如此。

### 2. CrowdGuard 架構與流程 (參考論文 Figure 2)

CrowdGuard 的運作流程可以概括為以下幾個主要步驟：

1.  **設置階段 (Setup Phase)：**
    *   每個客戶端和服務器初始化其安全隔離區 (TEE)。
    *   客戶端將其私有數據集加載到其本地 TEE 中。
    *   服務器和客戶端相互進行遠程證明，以驗證 TEE 的完整性和執行的代碼的真實性。

2.  **本地模型訓練：**
    *   (步驟 1 & 2) 服務器將當前全局模型 `Gt` 分發給選定的客戶端。客戶端在其本地 TEE 內使用本地數據訓練模型，得到本地模型 `L_i`，並將加密後的模型發送回服務器 TEE。

3.  **客戶端驗證迴路 (Client Validation Loop)：**
    *   (步驟 3) 服務器 TEE 將收集到的所有本地模型 `L_1, ..., L_n` 分發給被選為「驗證客戶端」的 TEEs。
    *   (步驟 4) 每個驗證客戶端的 TEE 使用其本地數據集 `D_j`，通過 **HLBIM 分析**來驗證收到的各個本地模型 `L_i` 是否存在後門。
    *   (步驟 5) 驗證客戶端向服務器 TEE 提交關於每個 `L_i` 是良性還是可疑的投票。

4.  **服務器端聚合與剪枝 (Server-Side Aggregation and Pruning)：**
    *   (步驟 6) 服務器 TEE 採用 **堆疊式聚類 (Stacked Clustering)** 方案來聚合所有驗證客戶端的投票，以抵抗惡意客戶端的操縱性投票。
    *   被標記為中毒的模型將被移除。

5.  **全局模型更新：**
    *   (步驟 7) 服務器 TEE 使用配置的聚合規則 (如 FedAVG，或其他如 Krum、Trimmed Mean 等) 聚合剩餘的良性本地模型，生成新的全局模型 `Gt+1`。
    *   新的全局模型分發給客戶端進行下一輪訓練。

### 3. 隱藏層後門檢測指標 (HLBIM) (參考 Algorithm 1)

HLBIM 是 CrowdGuard 的核心檢測機制，用於在客戶端 TEE 內分析模型。

*   **動機：** 後門攻擊即便不改變最終輸出，也可能在模型的隱藏層中留下痕跡。HLBIM 旨在捕捉這些隱藏層輸出 (Deep Layer Outputs, DLOs) 的顯著變化。
*   **矩陣生成：**
    1.  對於每個驗證樣本和每個待驗證的本地模型 `L_i` (以及全局模型 `Gt`)，提取所有隱藏層的 DLOs。
    2.  計算 `L_i` 的 DLOs 與 `Gt` 的 DLOs 之間的距離（例如，歐氏距離和餘弦距離）。
    3.  **關鍵步驟：** 將這些距離相對於驗證客戶端自身本地模型產生的 DLOs 進行**歸一化/比例化處理** (line 21 in Alg. 1 `dlo_rel = dlo / DLO_dist_local`)。這樣做的理由是，每個客戶端認為自己的模型是良性的，以此為基準可以更好地突顯其他模型的異常。
    4.  對處理後的距離值進行轉換（例如，減1後平方，保留符號，line 22 in Alg. 1）以放大差異。
    5.  按標籤類別對結果進行平均，然後扁平化以形成 HLBIM 矩陣。

### 4. 基於模型剪枝的投票決策 (參考 Algorithm 2)

在客戶端 TEE 中，利用 HLBIM 矩陣進行投票。

1.  **降維：** 使用主成分分析 (PCA) 處理 HLBIM 矩陣，主要關注第一主成分 (PC1)，因其能最大程度地區分不同模型。
2.  **顯著性檢驗：** 對 PC1 的值進行統計顯著性檢驗 (Student's t-test, F-test, Kolmogorov-Smirnov D-test) 以判斷是否存在異常分佈，指示後門的存在。同時檢查離群點。
3.  **迭代剪枝：**
    *   如果檢測到顯著差異，則使用層次凝聚聚類 (Hierarchical Agglomerative Clustering) 將模型分為兩簇。
    *   假定較小簇包含中毒模型，並將其剪枝（標記為惡意）。
    *   重複此過程，直到不再檢測到顯著差異或滿足中止條件（例如，剪枝超過一半模型）。
4.  **投票：** 最終，客戶端對每個模型是良性還是惡意進行投票。

### 5. 投票聚合 - 堆疊式聚類 (Stacked Clustering) (參考 Algorithm 3)

在服務器 TEE 中，聚合來自多個驗證客戶端的投票。

*   **第一層聚類 (多數決)：** 使用凝聚聚類 (Agglomerative Clustering) 將所有客戶端的二元投票向量分為兩簇。假定較大簇代表良性客戶端的投票。
*   **第二層聚類 (提取最頻繁投票模式)：** 對第一層選出的多數投票簇，使用 DBSCAN 提取其中最頻繁（最具代表性）的投票模式作為最終的聚合決策。
*   **魯棒性：** 這種兩級策略旨在抵抗高達 49% 的惡意客戶端合謀提供錯誤投票的情況。

### 6. 可信執行環境 (TEEs) 的角色

*   **客戶端 TEE：**
    *   保護客戶端的本地數據在驗證其他客戶端模型時不被洩露。
    *   確保 HLBIM 分析和投票決策過程的完整性。
*   **服務器 TEE：**
    *   保護從客戶端收集的本地模型不被服務器運營者（可能是惡意的 A_P）直接訪問。
    *   安全地執行投票聚合和模型聚合過程。
*   **遠程證明：** 在任何敏感數據或模型交換之前，客戶端和服務器 TEEs 相互證明，確保對方運行的是預期中的、未被篡改的代碼。

## 實作細節

*   **計算設置：** Python, PyTorch, Intel Xeon server with SGXv2, NVIDIA RTX A6000 GPU, Gramine (在 SGX 內執行 Python)。
*   **數據集：** CIFAR-10, MNIST。
*   **模型：** ResNet-18 (輕量版), CNN (類似 LeNet)。
*   **默認配置 (Default Configurations - Tab. IV in Appendix A)：**
    *   數據集：CIFAR-10
    *   客戶端數 `n=20` (參與 FL 和反饋迴路)
    *   後門類型：語義後門 (Semantic Backdoor)
    *   數據分佈：non-IID, `q=0` (表示每個客戶端數據標籤是 disjoint 的，每個客戶端一個主要標籤)
    *   中毒數據率 (PDR)：0.1
    *   中毒模型率 (PMR)：0.45 (20個客戶端中有9個惡意)
    *   自適應攻擊者：`α=0.7` (constrain-and-scale attack)
*   **對手模型 (Adversary Model)：**
    *   **中毒攻擊者 A_B：** 目標是注入後門 (目標 O1: 攻擊影響) 同時保持隱蔽 (目標 O2: 不被檢測)。完全控制 `n_a < n/2` 的客戶端，了解服務器和客戶端算法，可進行自適應攻擊。
    *   **隱私攻擊者 A_P：** 目標是重構客戶端的本地數據。假設其可任意控制聚合服務器，甚至部分客戶端以分析其他客戶端的本地模型。CrowdGuard 通過 TEEs 防禦此類攻擊。

## 實驗結果亮點

*   **高效檢測 (Table I)：** 在多種數據分佈 (IID, non-IID, Dirichlet, Normal)、不同中毒率、不同後門類型（像素、標籤翻轉、語義）、自適應攻擊等情況下，CrowdGuard 均達到了 100% TPR (真陽性率) 和 100% TNR (真陰性率)。
*   **保持模型性能 (R2 requirement)：** CrowdGuard 在沒有攻擊時，不會降低良性模型的性能。在有攻擊時，由於有效移除了惡意模型，MA (主任務準確率) 得到保護。
*   **魯棒性：**
    *   **Disjoint Data Scenario：** 即使客戶端數據完全不重疊，依然有效。
    *   **MNIST 數據集：** 證明了其非特定於某個數據集。
    *   **不同 PMR：** 即使在 PMR 高達 49% 的情況下依然有效。
    *   **自適應攻擊：** 能夠抵禦試圖最小化與全局模型差異或精確適應防禦算法的攻擊者。迭代剪枝和依賴其他客戶端數據進行驗證是關鍵。
*   **運行時開銷 (Table II)：**
    *   在 SGX TEE 內驗證 20 個模型的平均開銷約為 29.5 秒 (CPU)。GPU 加速可以顯著減少 DLO 預測時間。
    *   證明 (Attestation) 和剪枝的開銷很小。
*   **與現有方法比較 (Table III)：** 在默認場景下，CrowdGuard 的 BA 為 0%，MA 保持良好，TPR/TNR 均為 100%，優於多個 SOTA 防禦方法（如 Median, FoolsGold, Krum, Auror）。

## 結論

CrowdGuard 提出了一種新穎的、基於客戶端反饋和 TEE 的聯邦學習後門防禦框架。其核心創新包括 HLBIM 指標、基於顯著性的迭代剪枝算法以及魯棒的堆疊式投票聚合機制。實驗證明，CrowdGuard 能夠在各種複雜場景下有效識別並過濾中毒模型，同時保護客戶端數據隱私和模型性能，使其適用於真實世界的應用。
